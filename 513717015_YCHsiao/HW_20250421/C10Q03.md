![image](https://github.com/user-attachments/assets/458daa44-901d-4032-9966-bbc4c99f24b7)

10.3 In the regression model $y = \beta_1 + \beta_2 x + e$, assume $x$ is endogenous and that $z$ is a valid instrument.

a. Divide the denominator of $\hat{\beta}_2 = \frac{\text{cov}(z, y)}{\text{cov}(z, x)}$ by $\text{var}(z)$. Show that $\frac{\text{cov}(z, x)}{\text{var}(z)}$ is the coefficient of the simple regression with dependent variable $x$ and explanatory variable $z$.

解：
- $\hat{\beta}_2 = \frac{\text{cov}(z, y)}{\text{cov}(z, x)}$
- 把分母 $\text{cov}(z, x)$ 除以 $\text{var}(z)$:

  $\frac{\text{cov}(z, x)}{\text{var}(z)}$

- 這正是以 $x$ 為應變數、$z$ 為解釋變數的簡單線性回歸係數（第一階段回歸）。
- 第一階段回歸式：$x = \gamma_1 + \theta_1 z + \nu$，其中 $\theta_1 = \frac{\text{cov}(z, x)}{\text{var}(z)}$。

---

b. Divide the numerator of $\hat{\beta}_2 = \frac{\text{cov}(z, y)}{\text{cov}(z, x)}$ by $\text{var}(z)$. Show that $\frac{\text{cov}(z, y)}{\text{var}(z)}$ is the coefficient of a simple regression with dependent variable $y$ and explanatory variable $z$.

解：
- 把分子 $\text{cov}(z, y)$ 除以 $\text{var}(z)$:

  $\frac{\text{cov}(z, y)}{\text{var}(z)}$

- 這正是以 $y$ 為應變數、 $z$ 為解釋變數的簡單線性回歸係數。
- 回歸式： $y = \pi_0 + \pi_1 z + u$，其中 $\pi_1 = \frac{\text{cov}(z, y)}{\text{var}(z)}$。

---

c. In the model $y = \beta_1 + \beta_2 x + e$, substitute for $x$ using $x = \gamma_1 + \theta_1 z + \nu$ and simplify to obtain $y = \pi_0 + \pi_1 z + u$. What are $\pi_0$, $\pi_1$, and $u$ in terms of the regression model parameters and errors?

解：
- 代入 $x = \gamma_1 + \theta_1 z + \nu$ 到 $y = \beta_1 + \beta_2 x + e$:

  $y = \beta_1 + \beta_2 (\gamma_1 + \theta_1 z + \nu) + e$

  展開後：

  $y = (\beta_1 + \beta_2 \gamma_1) + \beta_2 \theta_1 z + (\beta_2 \nu + e)$

- 對比 reduced-form 方程式：

  $y = \pi_0 + \pi_1 z + u$

- 參數對應關係：

  $\pi_0 = \beta_1 + \beta_2 \gamma_1$  
  $\pi_1 = \beta_2 \theta_1$  
  $u = \beta_2 \nu + e$

---

d. Show that $\beta_2 = \frac{\pi_1}{\theta_1}$.

解：
- 從 c. 已知 $\pi_1 = \beta_2 \theta_1$
- 解出 $\beta_2$:

  $\beta_2 = \frac{\pi_1}{\theta_1}$

---

e. If $\hat{\pi}_1$ and $\hat{\theta}_1$ are the OLS estimators of $\pi_1$ and $\theta_1$, show that $\hat{\beta}_2 = \frac{\hat{\pi}_1}{\hat{\theta}_1}$ is a consistent estimator of $\beta_2 = \frac{\pi_1}{\theta_1}$. The estimator $\hat{\beta}_2 = \frac{\hat{\pi}_1}{\hat{\theta}_1}$ is an indirect least squares estimator.

解：
- 假設 $\hat{\pi}_1$ 和 $\hat{\theta}_1$ 是 $\pi_1$ 和 $\theta_1$ 的一致估計量（因為 OLS 在這些回歸中一致）。
- 根據 **Slutsky 定理**，比值 $\frac{\hat{\pi}_1}{\hat{\theta}_1}$ 是 $\beta_2 = \frac{\pi_1}{\theta_1}$ 的一致估計量。
- 這種透過回歸兩個方程式（reduced-form 和第一階段），再取比值得到 $\hat{\beta}_2$ 的方法，稱為 **間接最小平方法（Indirect Least Squares, ILS）**。
