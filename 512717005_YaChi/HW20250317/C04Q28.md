![image](https://github.com/user-attachments/assets/4869bfed-b156-4728-8a32-291e0bfe2d7e)

## a
```
# 載入資料
load("wa_wheat.rdata")

# 轉換為 data frame
data <- data.frame(
  YIELD = wa_wheat$northampton,
  TIME = wa_wheat$time
)

# 建立回歸模型
model1 <- lm(YIELD ~ TIME, data = data)
model2 <- lm(YIELD ~ log(TIME), data = data)
model3 <- lm(YIELD ~ TIME + I(TIME^2), data = data)  # 修正為包含線性項
model4 <- lm(log(YIELD) ~ TIME, data = data)

# 儲存模型
models <- list(model1, model2, model3, model4)
model_names <- c("Model 1: YIELD ~ TIME",
                 "Model 2: YIELD ~ log(TIME)",
                 "Model 3: YIELD ~ TIME^2",
                 "Model 4: log(YIELD) ~ TIME")

# 繪製 Fitted values
par(mfrow = c(2, 2))
for (i in 1:4) {
  model <- models[[i]]
  name <- model_names[i]
  fitted_vals <- fitted(model)
  
  plot(data$TIME, data$YIELD, col = "black", pch = 16,
       main = paste("Fitted:", name), ylab = "YIELD", xlab = "TIME")
  lines(data$TIME, fitted_vals, col = "blue", lwd = 2)
}

# 殘差圖
par(mfrow = c(2, 2))
for (i in 1:4) {
  plot(resid(models[[i]]), main = paste("Residuals of", model_names[i]), 
       ylab = "Residuals", xlab = "Index")
}

# QQ-Plot
par(mfrow = c(2, 2))
for (i in 1:4) {
  qqnorm(resid(models[[i]]), main = paste("QQ Plot of", model_names[i]))
  qqline(resid(models[[i]]), col = "red")
}

# Jarque-Bera 檢定
if (!require("tseries")) install.packages("tseries")
library(tseries)

jb_results <- data.frame(
  Model = model_names,
  P_Value = sapply(models, function(m) jarque.bera.test(resid(m))$p.value)
)
jb_results$Normality <- ifelse(jb_results$P_Value > 0.05, "Yes", "No")
print(jb_results)
```

## b
```

```

## c
```
# Shapiro-Wilk 檢定
cat("Summary Table:\n")
for (i in 1:4) {
  model <- models[[i]]
  sw_p <- shapiro.test(resid(model))$p.value
  cat(model_names[i], "\n")
  cat("  R² =", summary(model)$r.squared, "\n")
  cat("  Shapiro-Wilk p-value =", sw_p, "\n\n")
}

# 診斷異常值
model_best <- model3
n <- nrow(data)
p <- length(coef(model_best))

stud_res <- rstudent(model_best)
leverage <- hatvalues(model_best)
dfbetas_vals <- dfbetas(model_best)
dffits_vals <- dffits(model_best)

stud_threshold <- 2
lev_threshold <- 2 * (p / n)
dfbetas_threshold <- 2 / sqrt(n)
dffits_threshold <- 2 * sqrt(p / n)

unusual <- which(abs(stud_res) > stud_threshold |
                   leverage > lev_threshold |
                   apply(abs(dfbetas_vals), 1, max) > dfbetas_threshold |
                   abs(dffits_vals) > dffits_threshold)

if (length(unusual) > 0) {
    print(data.frame(Index = unusual,
                     Studentized_Residual = stud_res[unusual],
                     Leverage = leverage[unusual],
                     DFFITS = dffits_vals[unusual],
                     Max_DFBETAS = apply(abs(dfbetas_vals), 1, max)[unusual]))
} else {
    cat("No significant outliers detected.\n")
}
```

## d
```
# 預測 1997
data_train <- data[1:47, ]
model_train <- lm(YIELD ~ TIME + I(TIME^2), data = data_train)
new_data <- data.frame(TIME = 48)
pred <- predict(model_train, newdata = new_data, interval = "prediction", level = 0.95)

print(data.frame(Predicted_YIELD = pred[1, "fit"],
                 Lower_Bound = pred[1, "lwr"],
                 Upper_Bound = pred[1, "upr"],
                 Actual_YIELD = data$YIELD[48]))
```
