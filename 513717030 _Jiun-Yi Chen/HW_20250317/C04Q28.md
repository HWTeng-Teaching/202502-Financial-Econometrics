![424592543-ce0d5f6f-2a7d-46db-9d91-d59f8d161b70](https://github.com/user-attachments/assets/dc70829c-3278-4b32-b696-b5d37fe7872c)

(a) Estimate each of the four equations and compare

We have four functional forms relating wheat yield ($\text{YIELD}_t$) to time ($t$), using annual data for 1950–1997 (48 observations):
Linear (level–level)
$\text{YIELD}_t = \beta_0 + \beta_1,\text{TIME}_t + e_t$

Semi-log (level–logX)
$\text{YIELD}_t = \alpha_0 + \alpha_1,\ln(\text{TIME}_t) + e_t$

Log–linear (logY–levelX)
$\ln(\text{YIELD}_t) = \gamma_0 + \gamma_1,\text{TIME}_t + e_t$

Double-log (log–log)
$\ln(\text{YIELD}_t) = \phi_0 + \phi_1,\ln(\text{TIME}_t) + e_t$

Steps for each model

Estimate by OLS: Obtain the estimated coefficients (intercept and slope).

Plot fitted values and residuals: Check whether residuals show any trends, heteroskedasticity, or serial correlation.

Residual normality tests: For instance, Jarque–Bera or Shapiro–Wilk tests to see if residuals are approximately normally distributed.

Compare $R^2$ and other criteria: For log-based models, look at $R^2$ on the log scale and possibly the adjusted $R^2$.

Possible findings

Linear model ($\text{YIELD}_t = \beta_0 + \beta_1,\text{TIME}_t$) sometimes has increasing residual variance over time, indicating potential heteroskedasticity.

Semi-log model may not be conceptually ideal if $\ln(\text{TIME}_t)$ does not capture the yield pattern well.
Log–linear model ($\ln(\text{YIELD}_t) = \gamma_0 + \gamma_1,\text{TIME}_t$) often works well if yield grows at roughly an exponential rate over time.

Double-log model is often used to estimate elasticities, but $\ln(\text{TIME}_t)$ is less common unless the data suggest a power-law pattern over time.

Suppose that, after estimation and diagnostic checks, the log–linear model (3) is found to have more stable residuals, better normality, and a higher $R^2$ (in logs). In that case, we would prefer model (3):

$\ln(\text{YIELD}_t) = \gamma_0 + \gamma_1,\text{TIME}_t + e_t.$
\
(b) Interpret the time coefficient in your chosen specification

If the chosen model is

$\ln(\text{YIELD}_t) = \gamma_0 + \gamma_1,\text{TIME}_t + e_t,$

then the estimated slope $\hat{\gamma}_1$ represents the marginal effect of one additional year on the log of yield. In other words:

If $\hat{\gamma}_1 = 0.02$, it implies that each additional year increases $\ln(\text{YIELD}_t)$ by $0.02$ on average, which is roughly a $2%$ growth in yield per year.

More precisely, a change of $0.02$ in $\ln(\text{YIELD})$ corresponds to $e^{0.02}-1 \approx 2.02%$, but for small values we often approximate it as $2%$.

Hence, $\gamma_1$ can be viewed as the average annual growth rate of wheat yield in percentage terms.
\
(c) Use standardized residuals, LEVERAGE, DFBETAS, and DFFITS

Having selected model (3), you would run standard diagnostic checks to identify any influential observations or outliers:

Leverage (hat values)

Measures how far each observation’s explanatory variable(s) is from the mean. Observations with high leverage can disproportionately affect the regression fit.

DFBETAS
Checks how much an individual observation changes the estimated coefficients (e.g., $\gamma_0$, $\gamma_1$) when that observation is omitted. A rule of thumb is that values exceeding $\pm 2/\sqrt{n}$ may indicate influential points.

DFFITS

Measures how much an individual observation affects its own fitted value after being removed from the sample, standardized by an appropriate scale factor. Observations with $|\text{DFFITS}| > 2\sqrt{\frac{k+1}{n}}$ (where $k$ is the number of parameters) are considered influential.

In a time-series context, unusual years (e.g., extreme weather or policy changes) might appear as high-leverage or influential points.
\
(d) Use observations up to 1996 to estimate, then construct a 95% prediction interval for 1997

Re-estimate using 1950–1996 data (47 observations):
$\ln(\text{YIELD}_t) = \hat{\gamma}_0 + \hat{\gamma}_1,\text{TIME}_t.$

Predict 1997 (in logs):
$\widehat{\ln(\text{YIELD}_{1997})} = \hat{\gamma}_0 + \hat{\gamma}1,\text{TIME}{1997}.$

Construct the 95% prediction interval on the log scale:
\
$\widehat{\ln(Y_{1997})} \pm t_{\alpha/2,(n-2)} \sqrt{Var(\widehat{\ln(Y_{1997})}) + \hat{\sigma}^2}$

Here, $n = 47$ is the sample size (1950–1996), and $t_{\alpha/2,, (n-2)}$ is the critical $t$ value.

$\hat{\sigma}^2$ is the estimated variance of the residuals.

Exponentiate to return to the original scale:
$\Bigl[ \exp\bigl(\widehat{\ln(\text{YIELD}{1997})} - \dots\bigr), \exp\bigl(\widehat{\ln(\text{YIELD}{1997})} + \dots\bigr) \Bigr]. $
