![圖片](https://github.com/user-attachments/assets/0f018921-844c-446b-8bb5-264e9ae5da7c)


## (a)
The result of R programming.
```
Call:
lm(formula = MILES ~ INCOME + AGE + KIDS, data = vacation)

Residuals:
     Min       1Q   Median       3Q      Max 
-1198.14  -295.31    17.98   287.54  1549.41 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) -391.548    169.775  -2.306   0.0221 *  
INCOME        14.201      1.800   7.889 2.10e-13 ***
AGE           15.741      3.757   4.189 4.23e-05 ***
KIDS         -81.826     27.130  -3.016   0.0029 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 452.3 on 196 degrees of freedom
Multiple R-squared:  0.3406,	Adjusted R-squared:  0.3305 
F-statistic: 33.75 on 3 and 196 DF,  p-value: < 2.2e-16

> confint(model_ols, "KIDS", level = 0.95)
         2.5 %    97.5 %
KIDS -135.3298 -28.32302              
```

## (b)
Plot residuals of income and age:

INCOME:
![Q16 B1](https://github.com/user-attachments/assets/5edd6f3b-77c3-44cb-8f51-3908302042bb)

*Check whether heteroskedasticity exists:*

We can find that the residuals are more widely dispersed at higher levels of INCOME, this implies that high‑income households exhibit greater variability in miles traveled. we should then perform a White test to confirm.

AGE:
![Q16 B2](https://github.com/user-attachments/assets/edcfe4f7-05ab-453d-9517-f556851d43e2)

*Check whether heteroskedasticity exists:*

We can find that the residuals don't “fan out” (i.e. form a funnel shape),and the residuals are scattered evenly around the horizontal line, with no obvious pattern. We can provisionally assume homoskedasticity.

## (c)
using the Goldfeld-Quandt test:
```
Goldfeld-Quandt test

data:  MILES ~ INCOME + AGE + KIDS
GQ = 3.1041, df1 = 86, df2 = 86, p-value = 1.64e-07
alternative hypothesis: variance increases from segment 1 to 2
```
**H₀:**  
The error variances are equal between the low‐income and high‐income groups.  
$H_0: \sigma^2_{\text{first 90}} = \sigma^2_{\text{last 90}}$

**H₁:**  
The error variance in the high‐income group exceeds that in the low‐income group.  
$H_1: \sigma^2_{\text{last 90}} > \sigma^2_{\text{first 90}}$




**Decision at $\alpha = 0.05$**

1. Critical value:  
   $F_{0.95}(86,86)\approx1.4286$

2. Since  
   GQ = 3.1041 > 1.4286 , we reject 
   $H_0: \sigma^2_{\text{first 90}} = \sigma^2_{\text{last 90}}$

4. **Conclusion**: The error variance in the high‑income group (last 90 observations) is significantly larger than in the low‑income group (first 90 observations), indicating heteroskedasticity.

## (d)

| Method           | Lower bound (2.5%) | Upper bound (97.5%) |
|------------------|--------------------|---------------------|
| Traditional SE   | $-135.3298$        | $-28.3230$          |
| HC1 Robust SE    | $-139.3218$        | $-24.3311$          |

The traditional standard errors assume homoskedasticity, yielding a 95\% confidence interval for  $[-135.33,\,-28.32]$. In contrast, the HC1 robust standard errors account for heteroskedasticity, producing a wider interval of $[-139.32,\,-24.33]$, reflecting increased uncertainty when the homoskedasticity assumption is relaxed.

## (e)
Through R programing, we can get the result below.
```
(a):
> confint(model_ols, "KIDS", level = 0.95)
         2.5 %    97.5 %
KIDS -135.3298 -28.32302

(d)
> kid_coef <- coef(model_ols)["KIDS"]
> kid_se_robust <- sqrt(vcovHC(model_ols, type = "HC1")["KIDS", "KIDS"])
> ci_lower <- kid_coef - 1.9721 * kid_se_robust
> ci_upper <- kid_coef + 1.9721 * kid_se_robust
      KIDS       KIDS 
-139.32177  -24.33107

(e)
GLS
> confint(model_gls, "KIDS", level = 0.95)
         2.5 %    97.5 %
KIDS -119.8945 -33.71808

Robust GLS
> kid_coef <- coef(model_gls)["KIDS"]
> robust_gls_se <- sqrt(vcovHC(model_gls, type = "HC1")["KIDS", "KIDS"])
> ci_lower <- kid_coef - 1.9721 * robust_gls_se
> ci_upper <- kid_coef + 1.9721 * robust_gls_se
> c(ci_lower, ci_upper)
      KIDS       KIDS 
-121.41245  -32.20013 
```
After organzising the result, we can get the result below.
| Method                     | Lower bound (2.5%) | Upper bound (97.5%) | width of intervals |
|--------------------------|---------------------|----------------------|-----------|
| Conventional OLS SE              | $-135.3298$         | $-28.3230$           | $107.007$ |
| HC1 Robust SE            | $-139.3218$         | $-24.3311$           | $114.991$ |
| Conventional GLS (WLS)   | $-119.8945$         | $-33.7181$           | $86.176$  |
| Robust GLS (HC1)         | $-121.4125$         | $-32.2001$           | $89.212$  |


![圖片](https://github.com/user-attachments/assets/1ec0411b-012b-4404-ae6a-13435ec5b6a6)

### Difference Analysis

- **Interval Widths**  
  - *Conventional GLS (WLS)* produces the narrowest 95\% confidence interval ($\approx 86.18$), reflecting greatest efficiency when the variance‐structure assumption is correct.  
  - *Robust GLS (HC1)* yields a slightly wider interval ($\approx 89.21$), accounting for potential misspecification while still improving on OLS.  
  - *Traditional OLS SE* gives a wider interval ($\approx 107.01$), due to ignoring heteroskedasticity.  
  - *HC1 Robust OLS* has the widest interval ($\approx 114.99$), as it fully relaxes the constant‐variance assumption and thus captures the greatest level of uncertainty.

- **Interval Positioning**  
  - GLS‐based intervals tend to be shifted closer to zero (i.e. smaller magnitude), indicating more concentrated estimates of the coefficient under the weighted specification.  
  - OLS‐based intervals (both conventional and robust) are centered further away from zero, reflecting larger sampling variability.
