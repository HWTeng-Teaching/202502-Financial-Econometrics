![圖片](https://github.com/user-attachments/assets/fdfbef8a-8541-4048-99ea-05b549f56a2e)
# (a)
![圖片](https://github.com/user-attachments/assets/686cf2ae-f3f7-41b2-a816-593011ef98d2)
![Q28 A](https://github.com/user-attachments/assets/555752e9-f890-4b4f-ad0e-f6d3c096702c)
![Q28 A 2](https://github.com/user-attachments/assets/0cb6bba2-4faf-4885-8f2a-26553dc2a885)

### From the images and the result from the R: 
Characteristics of WAGE (Hourly Wage):

Most people earn between $10 and $20 per hour.

The distribution is right-skewed, meaning most people have lower wages, with just a few earning very high wages.

Because of a few very high earners, the average wage is usually higher than the median wage.

Characteristics of EDUC (Years of Education):

Most people have 12 years (high school) or 16 years (college) of education.

The data has clear peaks at these common levels: finishing high school (12 years) and finishing college (16 years).

There's also a smaller peak at higher education levels (18 years or more, for graduate degrees).

# (b)

![圖片](https://github.com/user-attachments/assets/74d64e4c-c7df-4f80-a11b-5080fe6fd072)
### From the result from the R:
The linear regression model is

$\hat{y}= -10.4 + 2.3968 x $

Slope (EDUC): 2.3968

On average, hourly wages increase by approximately $2.40 for each additional year of education.

This coefficient is highly significant (p-value < 2e-16), indicating that years of education significantly affect wages.

Adjusted R-squared: 0.2067

This means about 20.67% of the variation in wages is explained by education alone. Other factors also influence wages.

F-statistic: 313.3 (p-value < 2.2e-16)

This strongly supports the statistical significance of the overall regression model, indicating a strong relationship between education level and wages.

```
linear_model <- lm(wage ~ educ, data = data)
summary(linear_model)
```

# (c)

![Q28 C](https://github.com/user-attachments/assets/10f71aa5-4337-4e2b-8ddc-037e8d151dfb)
### From the image and the result from the R:
From the image produced in R, we can observe that as EDUC increases, the residuals also become larger.

This suggests that the error variance grows with education, violating assumption SR3.

If all assumptions SR1–SR5 hold, the residuals should not exhibit any noticeable patterns like this.

```
# Create a linear regression model (if not already established)
model <- lm(wage ~ educ, data = data)

# Calculate and store residuals
data$residuals <- residuals(model)

# View previous residuals
head(data$residuals)

library(ggplot2)

ggplot(data, aes(x = educ, y = residuals)) +
  geom_point(color = "green4", alpha = 0.6) +
  geom_hline(yintercept = 0, color = "tan3", linetype = "dashed") +
  labs(title = "Residuals vs. EDUC",
       x = "Years of Education (EDUC)",
       y = "Residuals") +
  theme_minimal()
```

# (d)
![圖片](https://github.com/user-attachments/assets/59da9302-4ade-4924-b031-89fedca6a15b)
```
#D
install.packages("broom")
install.packages("dplyr")

library(broom)
library(dplyr)

# original overall regression
model_all <- lm(wage ~ educ, data = data)

# Gender grouped regression
model_male <- lm(wage ~ educ, data = subset(data, female == 0))
model_female <- lm(wage ~ educ, data = subset(data, female == 1))

# race group regression
model_black <- lm(wage ~ educ, data = subset(data, black == 1))
model_non_black <- lm(wage ~ educ, data = subset(data, black == 0))

# Get results in tidy format
all_result <- tidy(model_all) %>% mutate(Group = "All")
male_result <- tidy(model_male) %>% mutate(Group = "Male")
female_result <- tidy(model_female) %>% mutate(Group = "Female")
black_result <- tidy(model_black) %>% mutate(Group = "Black")
non_black_result <- tidy(model_non_black) %>% mutate(Group = "Non-Black")

# Merge into a complete table
final_table <- bind_rows(all_result, male_result, female_result, black_result, non_black_result)

# Organize the order 
final_table <- final_table %>%
  select(Group, term, estimate, std.error, statistic, p.value) %>%
  arrange(term, Group)

# Indicate the final result
print(final_table)
```

# (e)
![圖片](https://github.com/user-attachments/assets/2bcd6a7c-112b-4f9e-9295-9b723829ca32)
After performing a quadratic regression, we identified a significant non-linear relationship between education and wages.  

From the regression results in R, the estimated equation is:  

$WAGE = \alpha_1 + \alpha_2 EDUC^2 + e = 4.9165 + 0.0891 EDUC^2$  

At 12 years of education, an additional year increases wages by approximately **\$2.1392** per hour.  

At 16 years of education, the wage increase per additional year rises to about **\$2.8523** per hour.  

In contrast, the linear regression model predicts a constant **\$2.40** per hour increase regardless of education level.  

This suggests that, unlike the linear model, the quadratic model captures how the return to education depends on the number of years already attained.

```
# E
# 建立 EDUC 的平方項
data$educ2 <- data$educ^2

quad_model <- lm(wage ~ educ2, data = data)
summary(quad_model)

# 提取 α₂ 的估計值
alpha2 <- coef(quad_model)["educ2"]


# EDUC = 12年時的邊際效果
marginal_effect_12 <- 2 * alpha2 * 12

# EDUC = 16年時的邊際效果
marginal_effect_16 <- 2 * alpha2 * 16

marginal_effect_12
marginal_effect_16
```

# (f)
![2 28 f](https://github.com/user-attachments/assets/70d266ab-0762-4ef9-b816-ed8b2125fd3c)

### From the image and the result from the R:
The quadratic model appears to fit the data slightly better than the linear equation, especially at lower levels of education.

quadratic model has lower SSE 216722.9 and linear model has SSE 220062.3)

```
# 建立線性回歸模型 (part b)
  linear_model <- lm(wage ~ educ, data = data)

# 建立二次回歸模型 (part e)
# 假設已經有 data$educ2 <- data$educ^2
quad_model <- lm(wage ~ educ2, data = data)

# 取得模型的擬合值
data$linear_fitted <- fitted(linear_model)
data$quad_fitted   <- fitted(quad_model)

# 繪製散佈圖 (wage 對 educ)
plot(
  data$educ, data$wage,
  pch = 16,                   # 散點符號
  col = "black",
  xlab = "教育年數 (educ)",
  ylab = "工資 (wage)",
  main = "線性模型與二次模型的擬合比較"
)

# 在圖上加入線性回歸模型擬合線
# abline() 適用於「wage ~ educ」形式的線性模型
abline(linear_model, col = "blue", lwd = 2)

# 在圖上加入二次回歸模型擬合曲線
# 需要將 x 座標排序，才可畫出平滑的曲線
sorted_educ <- sort(data$educ)
quad_fit_sorted <- fitted(quad_model)[order(data$educ)]
lines(sorted_educ, quad_fit_sorted, col = "red", lwd = 2)

# 加入圖例
legend(
  "topleft",
  legend = c("線性回歸", "二次回歸"),
  col = c("blue", "red"),
  lwd = 2
)
```
